{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2182ba14-bfa2-465b-aa00-07394ac16965",
   "metadata": {},
   "source": [
    "# Pandas I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e36a2b-3536-4ba2-b7d9-c1b88ec2605d",
   "metadata": {},
   "source": [
    "![Red Panda](images/red_panda.webp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a51598c-693c-47bd-bcde-4ae8c1dabaae",
   "metadata": {},
   "source": [
    "## <span class=\"objectives\">Objectives</span>\n",
    "\n",
    "+ Understand what the **Pandas** module provides\n",
    "+ Load data from **CSV** and other files\n",
    "+ Access data tables\n",
    "+ Extract rows and columns using conditions\n",
    "+ Calculate statistics for rows or columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde106d-0a36-441c-a82d-3d0dd6bf70dc",
   "metadata": {},
   "source": [
    "## About Pandas\n",
    "Pandas can:\n",
    "\n",
    "+ Read data from file, database, or other sources\n",
    "+ Deals with real-life issues such as invalid data\n",
    "+ Clean and reshape data\n",
    "+ Select and query data\n",
    "+ Use builtin statistical functions\n",
    "+ Work with NumPy and SciPy routines\n",
    "+ Export dataset to many formats\n",
    "\n",
    "*Pandas* is a package designed to make it easy to get, organize, and analyze large datasets. Its strengths lie in its ability to read from many different data sources, and to deal with real-life issues, such as missing,  incomplete, or invalid data. \n",
    "\n",
    "Pandas also contains functions for calculating means, sums and other kinds of analysis.\n",
    "\n",
    "For selecting desired data, Pandas has many ways to select and filter rows and columns. \n",
    "\n",
    "It is easy to integrate Pandas with NumPy, SciPy, Matplotlib, and other scientific packages. \n",
    "\n",
    "Pandas works best with two-dimensional (row/column) data, which can be visualized like a spreadsheet. However, using multiindexes, you can simulate three- or more dimensional data. \n",
    "\n",
    "The `groupby` method provides powerful split-apply-combine operations, combined with aggregate methods for powerful data summaries.  -- *groupby* enables transformations, aggregations, and easy-access to plotting functions. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP:</b> It is easy to emulate R's `plyr` package via pandas. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b>\n",
    "Here are some links that compare Pandas features to the equivalents in R:\n",
    "\n",
    "+ https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html\n",
    "+ https://towardsdatascience.com/cheat-sheet-for-python-dataframe-r-dataframe-syntax-conversions-450f656b44ca\n",
    "+ https://heads0rtai1s.github.io/2020/11/05/r-python-dplyr-pandas/\n",
    "</div>\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>Where did the name \"Pandas\" come from?</b>\n",
    "    </summary>\n",
    "    \n",
    "**PAN**el **DA**ta **S**ystem\n",
    "\n",
    "</details>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109f6dc-32ae-432d-99d3-feede04bd2d9",
   "metadata": {},
   "source": [
    "## Tidy data\n",
    "\n",
    "+ Tidy data is neatly grouped\n",
    "+ Data\n",
    "    - __Value__ = \"observation\"\n",
    "    - __Column__ = \"variable\"\n",
    "    - __Row__ = \"related observations\"\n",
    "+ Pandas best with tidy data\n",
    "\n",
    "A dataset contains _values_. Those values can be either numbers or strings. Values are grouped into _variables_, which are usually represented as _columns_. For instance, a column might contain \"unit price\" or \"percentage of NaCL\". A group of related values is called an _observation_. A _row_ represents an observation.  Every combination of row and column is a single value. \n",
    "\n",
    "When data is arranged this way, it is said to be \"tidy\". Pandas is designed to work best with tidy data. \n",
    "\n",
    "\n",
    "\n",
    "For instance, \n",
    "\n",
    "    Product    SalesYTD\n",
    "    oranges    5000\n",
    "    bananas    1000      \n",
    "    grapefruit 10000\n",
    "\n",
    "is tidy data. The variables are \"Product\" and \"SalesYTD\", and the observations are the names of the fruits and the sales figures. \n",
    "\n",
    "\n",
    "The following dataset is NOT tidy:\n",
    "\n",
    "    Fruit     oranges bananas grapefruit\n",
    "    SalesYTD  5000    1000    10000 \n",
    "\n",
    "To make selecting data easy, Pandas dataframes always have variable labels (columns) and observation labels (row indexes). A row index could be something simple like increasing integers, but it could also be a time series, or any set of strings, including a column pulled from the data set. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP</b> variables could be called \"features\" and observations could be called \"samples\"\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE</b>\n",
    "See <a href=\"https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\">The \"informal and code heavy version\" of Hadley Wickham's paper on tidy data</a> for a detailed discussion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ede6b-8e7d-4352-9ec7-df9865e1a4fd",
   "metadata": {},
   "source": [
    "## Pandas architecture\n",
    "+ Two main structures: Series and DataFrame\n",
    "+ Series – one-dimensional\n",
    "+ DataFrame – two-dimensional\n",
    "The two main data structures in pandas are the ((*Series*)) and the ((*DataFrame*)). A series is a one-dimensional  indexed list of values, something like an ordered dictionary. A DataFrame is is a two-dimensional grid, with both row and column indexes (like the rows and columns of a spreadsheet, but more flexible).\n",
    "\n",
    "You can specify the indexes, or pandas will use successive integers. Each row or column of a DataFrame is a Series. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE</b> Pandas used to support the <b>Panel</b> type, which is more more or less a collection of DataFrames, but Panel has been deprecated in favor of MultiIndex, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8b69e-82ed-47bb-bb39-1252fc9bba5c",
   "metadata": {},
   "source": [
    "## Setting up the notebook\n",
    "Import modules and configure settings needed for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b99ae-d6ec-4c7b-b29c-c93f693e1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import default_rng  # random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd73e7-f65d-4f26-905d-6a6f8537cf39",
   "metadata": {},
   "source": [
    "## Series\n",
    "* Indexed list of values\n",
    "* Similar to a dictionary, but ordered\n",
    "* Can get sum(), mean(), etc.\n",
    "* Use index to get individual values\n",
    "* indexes are not positional\n",
    "A ((Series)) is an indexed sequence of values. Each item in the sequence has an index. The default index is a set of increasing integer values, but any set of values can be used. \n",
    "\n",
    "For example, you can create a series with the values 5, 10, and 15 as follows:\n",
    "\n",
    "    s1 = pd.Series([5,10,15])\n",
    "\n",
    "This will create a Series indexed by [0, 1, 2]. To provide index values, add a second list:\n",
    "\n",
    "    s2 = pd.Series([5,10,15], ['a','b','c'])\n",
    "\n",
    "This specifies the indexes as 'a', 'b',  and 'c'. \n",
    "\n",
    "You can also create a Series from a dictionary. pandas will put the index values in order:\n",
    "\n",
    "    s3 = pd.Series({'b':10, 'a':5, 'c':15})\n",
    "\n",
    "Most of the time, however, you will get a Series by selecting one column or one row from a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08021a1a-2d2d-49e1-ba2f-10f2bc2b6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATA_POINTS = 10\n",
    "index = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "rng = default_rng()\n",
    "data = rng.standard_normal(NUM_DATA_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65092a9f-fcd6-4787-be85-99f7d6ee1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(data, index=index)  # create series with specified index\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b23a4e-ee41-471d-9e41-26b7d6715575",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series(data)  # create series with auto-generated index (0, 1, 2, 3, ...)\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e32e9-0f69-4b78-94bf-fd37de71dd80",
   "metadata": {},
   "source": [
    "### Selecting elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dd863-efbd-4207-8939-28f55590cef4",
   "metadata": {},
   "source": [
    "Select items from series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e64cab-4c9b-4d43-b8f4-6b7598758d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[['h', 'b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723475a-da7a-484f-ba28-8350abbc5ad8",
   "metadata": {},
   "source": [
    "Select slice of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd24e8c-1654-4242-882f-d220cccf7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1['b':'d'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68462806-6ec7-41c9-b548-0d1273595a84",
   "metadata": {},
   "source": [
    "Select by expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731db5e-9757-41ea-9f3f-fc6fd85abcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[s1 > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eede3cd-247e-45de-895b-cd928535fa42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6ed99-39e5-427f-a935-c7aedcbed9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sum(), mean(), min(), max():\")\n",
    "print(s1.sum(), s1.mean(), s1.min(), s1.max(), \"\\n\")  # get stats on series\n",
    "\n",
    "print(\"cumsum(), cumprod():\")\n",
    "print(s1.cumsum(), s1.cumprod(), \"\\n\")  # get stats on series\n",
    "\n",
    "print('a' in s1)  # test for existence of label\n",
    "print('m' in s1)  # test for existence of label\n",
    "print()\n",
    "\n",
    "s3 = s1 * 10  # create new series with every element of s1 multiplied by 10\n",
    "print(\"s3 (which is s1 * 10)\")\n",
    "print(s3, \"\\n\")\n",
    "\n",
    "s1['e'] *= 5\n",
    "\n",
    "print(\"boolean mask where s3 > 0:\")\n",
    "print(s3 > 0, \"\\n\")  # create boolean mask from series\n",
    "\n",
    "print(\"assign -1 where mask is true\")\n",
    "s3[s3 < 5] = -1  # set element to -1 where mask is True\n",
    "print(s3, \"\\n\")\n",
    "\n",
    "s4 = pd.Series([-0.204708, 0.478943, -0.519439])  # create new series\n",
    "print(\"s4.max(), .min(), etc.\")\n",
    "print(s4.max(), s4.min(), s4.max() - s4.min(), '\\n')  # print stats\n",
    "\n",
    "s = pd.Series([5, 10, 15], ['a', 'b', 'c'])  # create new series with index\n",
    "print(\"creating series with index\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071ae50-c4b3-4b06-aa08-b3bd6a96f101",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "+ Two-dimensional grid of values\n",
    "+ Row and column labels (indexes)\n",
    "+ Rich set of methods\n",
    "+ Powerful indexing\n",
    "A DataFrame is the workhorse of Pandas. It represents a two-dimensional grid of values, containing indexed rows and columns, something like a spreadsheet. \n",
    "\n",
    "There are many ways to create a DataFrame. They can be modified to add or remove rows/columns. Missing or invalid data can be eliminated or normalized. \n",
    "\n",
    "DataFrames can be initialized from many kinds of data. See the table on the next page for a list of possibilities.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>IMPORTANT</b> Most of the time you will create Series and Dataframes by reading data.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>FUN FACT</b> The DataFrame object is modeled after R's data.frame \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad648f-a820-4b94-8a8e-070717a1fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
    "rows = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "values = [  # sample data\n",
    "    [100, 110, 120, 130, 140],\n",
    "    [200, 210, 220, 230, 240],\n",
    "    [300, 310, 320, 330, 340],\n",
    "    [400, 410, 420, 430, 440],\n",
    "    [500, 510, 520, 530, 540],\n",
    "    [600, 610, 620, 630, 640],\n",
    "]\n",
    "\n",
    "df_simple = pd.DataFrame(values, index=rows, columns=columns) \n",
    "df_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b1844-0e4b-4d32-aaba-f2a9b37f3e63",
   "metadata": {},
   "source": [
    "Just column `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cce363-d9aa-439a-8565-655cb3c426ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae345d-8165-45dc-89c4-135120ea5843",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "* Supports many data formats\n",
    "* Reads headings to create column indexes\n",
    "* Auto-creates indexes as needed\n",
    "* Can used specified column as row index\n",
    "\n",
    "Pandas supports many different input formats. It will read file headings and use them to create column indexes. By default, it will use integers for row indexes, but you can specify a column to use as the index, or provide a list of index values.\n",
    "\n",
    "The **read_...()** functions have many options for controlling and parsing input. For instance, if large integers in the file contain commas, the thousands options let you set the separator as comma (in the US), so it will ignore them. \n",
    "\n",
    "`read_csv()` is the most frequently used function, and has many options. It can also be used to read generic flat-file formats. `read_table()` is similar to `read_csv()`, but doesn't assume CSV format. \n",
    "\n",
    "There are corresponding `to_...()` functions for many of the read functions. `to_csv()` and `to_excel()` are very useful. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> See the notebook <b>PandaInputDemo</b> for examples of reading most types of input.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP:</b> \n",
    "    See <a href=\"https://pandas.pydata.org/docs/user_guide/io.html\">the Pandas I/O documentation</a> for more information\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d427e010-26cd-4d58-88d3-4c5bd6f16b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.read_csv('../DATA/sales_records.csv')  # Read CSV data into dataframe. Pandas automatically uses the first row as column names\n",
    "df_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a39c49-5b29-4a4b-9387-f23d24c6f673",
   "metadata": {},
   "source": [
    "## Data summaries\n",
    "+ `describe()`  __basic statistical details__\n",
    "+ `info()` __per-column details (shallow memory use)__\n",
    "+ `info(memory_usage='deep')` __actual memory use__\n",
    "You can call the `describe()` and `info()` methods on a dataframe to get summaries of the kind of data contained. \n",
    "\n",
    "The `describe()` method, by default, shows statistics on all numeric columns. Add `include='int'` or `include='float'` to restrict the output to those types. `include='all'` will show all types, including \"objects\" (AKA text). \n",
    "\n",
    "To show just objects (strings), use `include='O'`. This will show all text columns. You can compare the *count* and *unique* values to check the _cardinality_ of the column, or how many distinct values there are. Columns with few unique values are said to have low cardinality, and are candidates for saving space by using the `Categorical` data type. \n",
    "\n",
    "The `info()` method will show the names and types of each column, as well as the count of non-null values. Adding `memory_usage='deep'` will display the total memory actually used by the dataframe. (Otherwise, it's only the memory used by the top-level data structures). \n",
    "\n",
    "These may be called on either Series or DataFrame object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b761e1-13e7-44ee-aa6d-9bc350e3bf81",
   "metadata": {},
   "source": [
    "### .info()\n",
    "Display all columns, their types, and how many valid (non-null) values for a series or a dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b0a82-9aa1-4244-8aa5-3c740c691e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99366944-5015-4ad2-8430-7ea337fe0081",
   "metadata": {},
   "source": [
    "###  `DATAFRAME.describe()`\n",
    "Get statistics on all numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb90eb5-3e6c-4978-b68f-94184d530f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sales.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80187915-fc36-4f6f-adae-e1bd6807c9e4",
   "metadata": {},
   "source": [
    "### `DATAFRAME.describe()` only integers\n",
    "Only describe integer columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e4a77-7977-4f38-bff0-65dd83e55d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.describe(include='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bd6b0-5c68-4105-9faf-fe974224de86",
   "metadata": {},
   "source": [
    "### DATAFRAME.describe() all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900a878-de28-4bf9-81f1-b18a89ea4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32848d34-85d3-4901-8a9b-373109bd72bf",
   "metadata": {},
   "source": [
    "## Basic Selecting\n",
    "\n",
    "+ Similar to normal Python or numpy\n",
    "+ Slices select rows\n",
    "\n",
    "One of the real strengths of pandas is the ability to easily select desired rows and columns. This can be done with simple subscripting, like normal Python, or extended subscripting, similar to numpy. In addition, pandas has special methods and attributes for selecting  data. \n",
    "\n",
    "For selecting  columns, use the column name as the subscript value. This selects the entire column. To select multiple columns, use a sequence (list, tuple, etc.) of column names.\n",
    "\n",
    "For selecting rows, use slice notation. This may not map to similar tasks in normal python. That is, dataframe[x:y] selects rows x through y, but dataframe[x] selects column x.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb6f469-57d2-462b-beba-eb6feab768c5",
   "metadata": {},
   "source": [
    "### Selecting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee7263-6d90-4fb1-9e3d-635fbd312079",
   "metadata": {},
   "source": [
    "### Selecting multiple columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7a235-50c2-4f08-b8e5-c40b9c712c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales[['Region', 'Item Type', 'Units Sold']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e11f30-8312-45fa-a199-48d854842424",
   "metadata": {},
   "source": [
    "#### Selecting with dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ec9f16-08a0-41f9-994c-c90f5a72418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.Country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94744f0c-1c37-4b30-85a4-f6991047a7e4",
   "metadata": {},
   "source": [
    "#### Selecting multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6daf0a5-ad28-4753-8c00-974daa96f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sales[['Region', 'Country', 'Item Type']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca786ac-213c-4a73-8995-b0bfd647b0ba",
   "metadata": {},
   "source": [
    "## Using .loc and .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf75fb7-4b6d-4918-8770-b3bc2d5e35f1",
   "metadata": {},
   "source": [
    "### Using .loc\n",
    "+ `loc[__row-spec__,__col-spec__]` for names (strings or numbers)\n",
    "+ `.loc[]` row or column specs can be\n",
    "    - single name\n",
    "    - iterable of names\n",
    "    - range (inclusive) of names\n",
    "\n",
    "The `.loc` and `.iloc` indexers provide more extensive and consistent selecting of rows and columns for dataframes. They both work exactly the same way, but `.loc` uses only row and column _names_, and `.iloc` uses only _positions_.\n",
    "\n",
    "Both indexers use the _getitem_ operator `[]`, with the syntax `[row-specifier, column-specifier]`. \n",
    "\n",
    "For `.loc[]`, the specifier can be either a single name, an iterable of names, or a range of names. The end of a range is inclusive. \n",
    "\n",
    "For `.iloc[]`, the specifier can be either a single numeric index (0-based), iterable of indexes, or a range of indexes. The end of a range is exclusive. \n",
    "\n",
    "To select all rows, or all columns, use `:`.\n",
    "\n",
    "The `.at[]` property can be used to select a single value at a given row and column: `df.at[47, \"color\"]`. This is a shortcut for `.loc[row, col]`.\n",
    "\n",
    "For both `.loc()` and `.iloc()`, omit the column specifier to select all columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f315695-a91a-4e4a-9e73-9b756c81c0ad",
   "metadata": {},
   "source": [
    "### Using.iloc\n",
    "\n",
    "+ `loc[__row-spec__,__col-spec__]` for names (strings or numbers)\n",
    "+ `.loc[]` row or column specs can be\n",
    "    - single name\n",
    "    - iterable of names\n",
    "    - range (inclusive) of names\n",
    "+ `.iloc[__row-spec__,__col-spec__]` for 0-based position (integers only)\n",
    "+ `.iloc[]` row or column specs can be\n",
    "    - single number\n",
    "    - iterable of numbers\n",
    "    - range (exclusive) of numbers\n",
    "\n",
    "The `.loc` and `.iloc` indexers provide more extensive and consistent selecting of rows and columns for dataframes. They both work exactly the same way, but `.loc` uses only row and column _names_, and `.iloc` uses only _positions_.\n",
    "\n",
    "Both indexers use the _getitem_ operator `[]`, with the syntax `[row-specifier, column-specifier]`. \n",
    "\n",
    "For `.loc[]`, the specifier can be either a single name, an iterable of names, or a range of names. The end of a range is inclusive. \n",
    "\n",
    "For `.iloc[]`, the specifier can be either a single numeric index (0-based), iterable of indexes, or a range of indexes. The end of a range is exclusive. \n",
    "\n",
    "To select all rows, or all columns, use `:`.\n",
    "\n",
    "The `.at[]` property can be used to select a single value at a given row and column: `df.at[47, \"color\"]`. This is a shortcut for `.loc[row, col]`.\n",
    "\n",
    "NOTE: For `.loc()` and `.iloc()`, the column specifier can be omitted, which will select all columns for those rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d314e9-cdfe-4907-b8a9-5c8cfaed0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc['b', 'delta'] \n",
    "\n",
    "\n",
    "# df.loc['b']\n",
    "\n",
    "# df.loc[:,'delta']\n",
    "\n",
    "\n",
    "# df.loc['b':'d', :]\n",
    "# df.loc['b':'d']\n",
    "\n",
    "# df.loc[:, 'beta':'delta']\n",
    "\n",
    "# df.loc['b':'d', 'beta':'delta']\n",
    "\n",
    "# df.loc[['b', 'e', 'a']]\n",
    "\n",
    "# df.loc[:, ['gamma', 'alpha', 'epsilon']]\n",
    "\n",
    "# df.loc[['b', 'e', 'a'], ['gamma', 'alpha', 'epsilon']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e6acc-c23c-40c9-9ef6-318a6a3b1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use real data ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000d672-be3c-4f69-bcb7-6f7dae990b59",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "* Operation is applied across rows and columns\n",
    "* Can be restricted to selected rows/columns\n",
    "* Sometimes called vectorization\n",
    "* Use apply() for more complex operations\n",
    "If you multiply a dataframe by some number, the operation is broadcast, or vectorized, across all values. This is true for all basic math operations. \n",
    "\n",
    "The operation can be restricted to selected columns. \n",
    "\n",
    "For more complex operations, the `apply()` method will apply a function that selects elements. You can use the name of an existing function, or supply a user-defined function.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP:</b> For simple functions, use the <em>lambda</em> (inline) syntax for defining the function.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df2b5f-4995-4a38-bbef-9f7344a8f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "# USE REAL DATA not this crap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf03a2-30e6-4931-b3ab-2e07492de5a8",
   "metadata": {},
   "source": [
    "## Counting unique occurrences\n",
    "+ Use `.value_counts()`\n",
    "+ Called from column or dataframe\n",
    "\n",
    "To count the unique occurrences within a column, call the method `value_counts()` on the column.\n",
    "\n",
    "It returns a `Series` object with the column values and their counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584d759-7b19-4a3c-abcb-e980123128f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "vc = df_sales['Region'].value_counts()\n",
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cd145-c040-4133-af43-c62f55007259",
   "metadata": {},
   "source": [
    "You can also call `value_counts()` on the dataframe and pass the column name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999f4da-2c93-4a77-810e-7b4c983851f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "vc = df_sales.value_counts('Region')\n",
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b56ae5a-1cb0-4877-a9e7-6cde891e88a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "To show the percentages of each value, add the `normalize` argument with a true value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4838936-01bf-4d32-9378-376f5d50fb8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "vc = df_sales.value_counts('Region', normalize=True)\n",
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f8619-f290-42de-9cb3-ad0382d5f765",
   "metadata": {},
   "source": [
    "## Creating new columns\n",
    "+ Assign to column with new name\n",
    "+ Use normal operators with other columns\n",
    "  \n",
    "For simple cases, it's easy to create new columns. Just assign a Series-like object to a new column name. The easy way to do this is to combine other columns with an operator or function. \n",
    "\n",
    "Any iterable object can be used, as long as its length matches the number of rows in the dataframe. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>TIP:</b> If you assign a single value to a column, it will be replicated on all rows. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768db476-b2b4-4bca-adc1-8644d51c100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['alpha', 'beta', 'gamma', 'delta', 'epsilon']\n",
    "index = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "values = [\n",
    "    [100, 110, 120, 130, 140],\n",
    "    [200, 210, 220, 230, 240],\n",
    "    [300, 310, 320, 330, 340],\n",
    "    [400, 410, 420, 430, 440],\n",
    "    [500, 510, 520, 530, 540],\n",
    "    [600, 610, 620, 630, 640],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(values, index=index, columns=cols)\n",
    "\n",
    "def times_ten(x):\n",
    "    return x * 10\n",
    "\n",
    "df['zeta'] = df['delta'] * df['epsilon'] # product of two columns\n",
    "df['eta'] = times_ten(df.alpha) # user-defined function\n",
    "df['theta'] = df.sum(axis=1)  # sum each row\n",
    "df['iota'] = df.mean(axis=1)  # avg of each row\n",
    "df['kappa'] = df.loc[:,'alpha':'epsilon'].mean(axis=1)\n",
    "# column kappa is avg of selected columns\n",
    "\n",
    "df['junk'] = \"JUNK\"\n",
    "df['toast'] = range(6)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb672d1-8923-46a8-a1ec-fef3e2550502",
   "metadata": {},
   "source": [
    "To remove columns or rows, use the `drop()` method, with the appropriate labels. Use `axis=1` to drop columns, or axis=0 to drop rows.\n",
    "## Removing entries\n",
    "* Remove rows or columns\n",
    "* Use drop() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f1f8d-174c-4311-8948-7ca6a268b4e1",
   "metadata": {},
   "source": [
    "%load ~/py/common/examples/pandas_drop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8cd484-917c-4a9f-bef1-d6edc565ab1c",
   "metadata": {},
   "source": [
    "## Useful pandas methods\n",
    "\n",
    "See **Methods and attributes for fetching DataFrame/Series data** in the **PandasResources** notebook for DataFrame/series methods and attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb39cf1-6e4b-4028-b6ba-d0e8da355e07",
   "metadata": {},
   "source": [
    "## Chapter Review\n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What two-dimensional data structure is the \"workhorse\" of Pandas?</b>\n",
    "    </summary>\n",
    "DataFrame\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What method gives a statistical summary of numeric columns?</b>\n",
    "    </summary>\n",
    ".describe()\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>Are DataFrame values read-only?</b></b>\n",
    "    </summary>\n",
    ".info()\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What method will count the distinct values in a column?</b>\n",
    "    </summary>\n",
    "value_counts()\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What _accessor_ makes it easy to select rows and columns by labels?</b>\n",
    "    </summary>\n",
    ".loc\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What method shows all columns and their data types?</b>\n",
    "    </summary>\n",
    ".info()\n",
    "</details> \n",
    "\n",
    "<details>\n",
    "    <summary>\n",
    "        <b>What method can delete entire rows or columns?</b>\n",
    "    </summary>\n",
    ".drop()\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba02dfe-e49b-42e0-888f-9a42173749fb",
   "metadata": {},
   "source": [
    "TODO: better labs\n",
    "\n",
    "TODO: read in a simple csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4b4e0-0f25-4f95-83fa-98214d5be150",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "TODO: better labs\n",
    "\n",
    "TODO: read in a simple csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334b567-171a-47a0-b141-f821c7163916",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Read in the file `sales_records.csv` as shown in the early part of the chapter. Add three new columns to the dataframe:\n",
    "\n",
    "+ Total Revenue (__units sold x unit price__)\n",
    "+ Total Cost (__units sold x unit cost__)\n",
    "+ Total Profit (__total revenue - total cost__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c3a9a7-66e2-4c89-bdae-ab8a772e7353",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The file `parasite_data.csv`, in the DATA folder, has some results from analysis on some intestinal parasites (not that it matters for this exercise...). \n",
    "Read parasite_data.csv into a DataFrame. Print out all rows where the Shannon Diversity is >= 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c34e98-e61a-4f71-ae2c-f56c7757676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d99f2-c5c6-42b0-8265-24af278758bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
